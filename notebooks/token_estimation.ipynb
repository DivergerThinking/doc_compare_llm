{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiktoken import get_encoding\n",
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fitz.open('../data/directiva_residuos/2008_98_ce_boetxt.pdf') as doc:\n",
    "    out_text_2008= \"\"\n",
    "    for page in doc:\n",
    "        text = page.get_text()\n",
    "        out_text_2008 = out_text_2008 + \"\\n\\n\" + text\n",
    "with fitz.open('../data/directiva_residuos/2018_851_boetxt.pdf') as doc:\n",
    "    out_text_2018 = \"\"\n",
    "    for page in doc:\n",
    "        text = page.get_text()\n",
    "        out_text_2018 = out_text_2018 + \"\\n\\n\" + text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/directiva_residuos/mods_2018.json') as file:\n",
    "    mods_2018 = eval(file.read())\n",
    "with open('../data/directiva_residuos/articles_2008.json') as file:\n",
    "    articles_2008 = eval(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_2008 = encoder.encode(out_text_2008)\n",
    "tokens_2018 = encoder.encode(out_text_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_articles_2008 = encoder.encode(\"\\n\".join(articles_2008.values()))\n",
    "tokens_mods_2018 = encoder.encode(\"\\n\".join(mods_2018.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_token_pricing = {\n",
    "    \"gpt-4-8k\": {\"input\": 0.03/1000, \"output\": 0.06/1000, \"context_len\": 8000},\n",
    "    \"gpt-4-32k\": {\"input\": 0.06/1000, \"output\": 0.12/1000, \"context_len\": 32000},\n",
    "    \"gpt-3.5-Turbo-4k\": {\"input\": 0.0015/1000, \"output\": 0.002/1000, \"context_len\": 4000},\n",
    "    \"gpt-3.5-Turbo-16k\": {\"input\": 0.003/1000, \"output\": 0.004/1000, \"context_len\": 16000},\n",
    "    \"claude_instant-100k\": {\"input\": 1.63/1000000, \"output\": 5.51/1000000, \"context_len\": 100000},\n",
    "    \"claude_2-100k\": {\"input\": 11.02/1000000, \"output\": 32.68/1000000, \"context_len\": 100000},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24332, 41562)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_2008), len(tokens_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14934, 21211)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_articles_2008), len(tokens_mods_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4599199999999999"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_token_pricing[\"gpt-4-8k\"][\"input\"] * len(tokens_2008)*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean text and extract articles\n",
    "Two scenarios:\n",
    "1. The tasks are solved properly with just one prompt call\n",
    "2. The tasks needs one prompt call for cleaning text and another one for article extraction\n",
    "\n",
    "Assumptions:\n",
    "- The output has 90% of input tokens\n",
    "- All models can be applied sequentially so no context length limitations are taken into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_task_cost(\n",
    "    input_token_len: int,\n",
    "    output_token_len: int,\n",
    "    cost_dict: dict,\n",
    "    sys_prompt_token_len: int = 1000,\n",
    "    verbose: bool = False,\n",
    ") -> float:\n",
    "    # n_call = two times input call since needs output for each call\n",
    "    n_calls = math.ceil(input_token_len / cost_dict[\"context_len\"]) * 2\n",
    "    sys_prompt_cost = sys_prompt_token_len * n_calls * cost_dict[\"input\"]\n",
    "    input_cost = input_token_len * cost_dict[\"input\"]\n",
    "    output_cost = output_token_len * cost_dict[\"output\"]\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"\"\"\n",
    "sys_prompt_cost = {sys_prompt_cost}\n",
    "input_cost = {input_cost}\n",
    "output_cost = {output_cost}\n",
    "\"\"\"\n",
    "        )\n",
    "    return round(sys_prompt_cost + input_cost + output_cost, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_cost(\n",
    "    model_cost_dict: dict, input_token_len: int, output_ratio: float = 0.85, sys_prompt_tokens: int = 1000\n",
    ") -> dict:\n",
    "    models_costs = {}\n",
    "    for model_name, cost_dict in model_cost_dict.items():\n",
    "        models_costs[model_name] = get_single_task_cost(\n",
    "            input_token_len, input_token_len * output_ratio, cost_dict, sys_prompt_tokens\n",
    "        )\n",
    "    return models_costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1\n",
    "The tasks are solved properly with just one prompt call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_input = len(tokens_articles_2008) + len(tokens_mods_2018)\n",
    "s1_output_ratio = 0.85\n",
    "s1_sys_prompt_token_len = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_costs = get_models_cost(api_token_pricing, s1_input, s1_output_ratio, s1_sys_prompt_token_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4-8k': 3.23,\n",
       " 'gpt-4-32k': 6.1,\n",
       " 'gpt-3.5-Turbo-4k': 0.15,\n",
       " 'gpt-3.5-Turbo-16k': 0.25,\n",
       " 'claude_instant-100k': 0.23,\n",
       " 'claude_2-100k': 1.42}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 2\n",
    "The tasks needs one prompt call for cleaning text and another one for article extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8504999999999999"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chained token reduction over tasks\n",
    "0.9*0.945"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_1_input = len(tokens_articles_2008) + len(tokens_mods_2018)\n",
    "s2_1_output_ratio = 0.945\n",
    "s2_2_input = s2_1_input * s2_1_output_ratio\n",
    "s2_2_output_ratio = 0.9\n",
    "s2_sys_prompt_token_len = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_1_costs = get_models_cost(api_token_pricing, s2_1_input, s2_1_output_ratio, s2_sys_prompt_token_len)\n",
    "s2_2_costs = get_models_cost(api_token_pricing, s2_2_input, s2_2_output_ratio, s2_sys_prompt_token_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4-8k': 6.6,\n",
       " 'gpt-4-32k': 12.49,\n",
       " 'gpt-3.5-Turbo-4k': 0.29000000000000004,\n",
       " 'gpt-3.5-Turbo-16k': 0.5,\n",
       " 'claude_instant-100k': 0.48,\n",
       " 'claude_2-100k': 2.94}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2_costs = {}\n",
    "for model_name in s2_1_costs.keys():\n",
    "    s2_costs[model_name] = s2_1_costs[model_name] + s2_2_costs[model_name]\n",
    "s2_costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence interval costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4-8k': {'min': 3.23, 'max': 6.6},\n",
       " 'gpt-4-32k': {'min': 6.1, 'max': 12.49},\n",
       " 'gpt-3.5-Turbo-4k': {'min': 0.15, 'max': 0.29000000000000004},\n",
       " 'gpt-3.5-Turbo-16k': {'min': 0.25, 'max': 0.5},\n",
       " 'claude_instant-100k': {'min': 0.23, 'max': 0.48},\n",
       " 'claude_2-100k': {'min': 1.42, 'max': 2.94}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_costs = {}\n",
    "for model_name in s2_costs.keys():\n",
    "    min_max_costs[model_name] = {\"min\": s1_costs[model_name], \"max\":  s2_costs[model_name]}\n",
    "min_max_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text clean and split cost by model in dollars:\n",
      "  Model gpt-4-8k:\n",
      "    Min cost 3.23$\n",
      "    Max cost 6.6$\n",
      "  Model gpt-4-32k:\n",
      "    Min cost 6.1$\n",
      "    Max cost 12.49$\n",
      "  Model gpt-3.5-Turbo-4k:\n",
      "    Min cost 0.15$\n",
      "    Max cost 0.29000000000000004$\n",
      "  Model gpt-3.5-Turbo-16k:\n",
      "    Min cost 0.25$\n",
      "    Max cost 0.5$\n",
      "  Model claude_instant-100k:\n",
      "    Min cost 0.23$\n",
      "    Max cost 0.48$\n",
      "  Model claude_2-100k:\n",
      "    Min cost 1.42$\n",
      "    Max cost 2.94$\n"
     ]
    }
   ],
   "source": [
    "cost_text = \"Text clean and split cost by model in dollars:\"\n",
    "for k, v in min_max_costs.items():\n",
    "    cost_text = cost_text + f\"\\n  Model {k}:\"\n",
    "    cost_text = cost_text + f\"\\n    Min cost {v['min']}$\"\n",
    "    cost_text = cost_text + f\"\\n    Max cost {v['max']}$\"\n",
    "print(cost_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmdiff_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
